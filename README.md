# SddF - Scalable Duplicate Detection Framework utilizing Apache
SddF is supposed to be a scalable distributed duplicate detection framework.
Apache Spark is used as distributed computing framework.
SddF is the result of my master's thesis in computational science.
It is still a prototype and not supposed to be used in production.

# Getting started
There is no binary release of SddF at the moment.
Therefor you have to build it on your own.
The following lines are briefly describing how to get started.

## Build SddF
* Clone the sddf repository
* Install sbt
* Run sbt publishLocal to compile SddF and make it available to other projects locally.

## Run Example
* Clone the sddf-example repository
* Download scala ide
* Run sbt eclipse
* Open eclipse and import the example project
* Run the example class

For any further information read my thesis.
I will include the link as soon as it is published.

# License
SddF is licensed under the GPLv3.
